# üëã Hi, I'm Riya

<div align="center">
  <img
    src="https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExYjBpYWNwMXJ2ZmttenNvbTZxbXVnZWlnb205aWQ1eWV5c2luMm1sYSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/VbnUQpnihPSIgIXuZv/giphy.gif" width="600" />
</div>

<br/>

**Software Engineer** | Building end-to-end AI/ML systems | *Turning coffee into JSON*

üéØ **Applied AI/ML Engineer in training** ‚Äî Currently in the **"build, break, cry, fix, learn"** phase. I ship projects to understand how AI systems work in practice (and occasionally how to bankrupt myself with OpenAI API credits).

---

## üíº Open to Opportunities

**Seeking**: Applied AI/ML Engineering roles where I can turn my spaghetti code into production pipelines.

**What I Bring**:
- **Production Mindset**: I know that "it works in the notebook" is a lie.
- **Cost Optimization**: I reduced token costs by 73% because I'm cheap.
- **Full-Stack ML**: I can fine-tune a model *and* center a `<div>` (okay, maybe just the model part).

üìß **Email**: riyasangwandec19@gmail.com  
üíº **LinkedIn**: [linkedin.com/in/riyasangwan](https://linkedin.com/in/riyasangwan/)  

---

## üõ†Ô∏è What I've Shipped (and barely survived)

### 1. [AI Agent Framework](https://github.com/ria-19/ai_agent) ‚Äî Hybrid ReAct + Reflexion Architecture

**The Project**: A "Dual-Brain" agent that knows when to "Think Fast" and "Think Slow". Basically, it has better impulse control than I do.

- **The Struggle**: At one point, the agent got into a loop apologizing to itself for 40 turns. I fixed it.
- **Engineering Wins**:
    - **Parser Hardening**: Zero crashes across 100+ runs (after fighting Regex for 3 days).
    - **Cost Optimization**: **73% reduction** in token usage. My wallet thanked me.
    - **Architecture**: Implements ReAct (System 1) + Reflexion (System 2).

**Status**: v0.2 Stable | [View Project ‚Üí](https://github.com/ria-19/ai_agent)

---

### 2. Semantic Router ‚Äî Fine-Tuned Function Calling Model

**The Problem**: GPT-4 is smart but expensive. Llama-3.1-Instruct is capable, but it's too "chatty" for automated pipelines. It often wraps JSON in conversational fluff ("Sure! Here is the code...") or hallucinates arguments for complex custom tools like my Python Sandbox.

**My Solution**: Using QLoRA and Unsloth to fine-tune a specialized adapter specifically for accurate function calling. This forces the model to ignore conversational norms and output raw, executable JSON schemas, running efficiently on a single T4 GPU (Local/Colab).

- **Progress**: 
    - ‚úÖ Generated synthetic training data for internal tools (Sandbox Exec, File Manager, Hybrid Search).
    - üöß Training the LoRA adapter via Unsloth (Squeezing "Senior Engineer" performance out of 16GB VRAM).
    - üìä Target: 0% Syntax Errors, 100% Valid JSON execution.
- **Goal**: Turn a generalist 8B model into a deterministic surgical instrument for code manipulation.

**Status**: Active Development (Baking the weights) | [View Project ‚Üí](https://github.com/ria-19/semantic_router)

---

### 3. [RepoRAG](https://github.com/ria-19/reporag) ‚Äî Chat with your Codebase

**The Project**: A RAG system because reading documentation is hard.

- **The "Aha!" Moment**: I realized that blindly chopping code into 500-token chunks is a terrible idea. Implemented **AST-based chunking** so the LLM actually sees full functions.
- **Results**: Accuracy jumped from 45% ‚Üí 82%. The other 18% is the model confidently lying.

**Status**: V1 Shipped | [View Project ‚Üí](https://github.com/ria-19/reporag)

---

### 4. Customer Segmentation ML System

**The Project**: Grouping customers based on spending habits so marketing teams can target them better.

- **Key Learning**: My initial model was garbage (Silhouette score 0.32). Turned out real data is messy and has outliers. Who knew? 
- **The Fix**: Winsorization + proper preprocessing = Score 0.58.
- **Performance**: Processes 10K records in 2.3s. Faster than I can open Excel.

**Status**: V1 Shipped

---

## ‚ö° Tech Stack (The tools I yell at)

<div align="center">
  <img src="https://skillicons.dev/icons?i=python,pytorch,docker,aws,gcp,fastapi,postgres,git,linux,vscode" />
</div>

<br/>

**ML/AI**: PyTorch (Love/Hate), Transformers, RAG, LoRA  
**LLMs**: Llama-3 (My best friend), GPT-4 (My expensive friend), Groq  
**Infrastructure**: Docker (Because "it works on my machine" is not a valid excuse)  
**Vibe Check**: ‚òï Coffee, üéß Lo-Fi Beats, üêõ Debugger  

---

## üìä How I Think About ML Systems

I focus on building systems that work reliably in production, not just in a sterile Jupyter Notebook.

**Principles I follow**:

1.  **Fail Gracefully**: If the LLM hallucinates, the system catches it. If *I* hallucinate, hopefully code review catches it.
2.  **Data Quality First**: 3 days of debugging a model usually ends with realizing I fed it garbage data.
3.  **Cost Awareness**: I treat API tokens like actual gold coins. We optimize for the cheapest model that works.

---

## ü§ù Open to Collaboration

I'm actively seeking:

- **Mentorship**: Please teach me how to fix `CUDA error: device-side assert triggered` without questioning my life choices.
- **Collaborations**: Building cool stuff with other engineers.
- **Jobs**: *Please hire me, I promise I write tests.*

---

<div align="center">

<img src="https://media.giphy.com/media/du3J3cXyzhj75IOgvA/giphy.gif" width="150" />

**‚≠ê Star my repos if you found them cool! (It validates my existence)**

</div>
